# Model Uploader - Upload ML models to MinIO to be served by Triton Inference Server

Do this with a Python script inside a docker container. Run this as a job in kubernetes.
[link](https://www.developerfiles.com/upload-files-to-s3-with-python-keeping-the-original-folder-structure/)

- Use [os.walk](https://docs.python.org/3/library/os.html?highlight=os%20walk)
- Python AWS [sdk](https://aws.amazon.com/sdk-for-python/)
